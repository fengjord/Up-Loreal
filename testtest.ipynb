{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'I¡¯ve been using this serum for a few days now and I can already see a great difference! I use it right after I use the gel wash and it makes my skin feel soft,  moisturized and fresh. I also love how glowing it makes my skin look. One of my favourite things about this serum is that it¡¯s a 3 in 1 formula. I would totally recommend using this!'\n",
    "\n",
    "txt=txt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import stanza\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 13:17:39 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-11-30 13:17:39 INFO: Use device: cpu\n",
      "2021-11-30 13:17:39 INFO: Loading: tokenize\n",
      "2021-11-30 13:17:39 INFO: Loading: pos\n",
      "2021-11-30 13:17:39 INFO: Loading: lemma\n",
      "2021-11-30 13:17:39 INFO: Loading: depparse\n",
      "2021-11-30 13:17:39 INFO: Loading: sentiment\n",
      "2021-11-30 13:17:40 INFO: Loading: constituency\n",
      "2021-11-30 13:17:40 INFO: Loading: ner\n",
      "2021-11-30 13:17:40 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'NN'), ('ve', 'VBP'), ('been', 'VBN'), ('using', 'VBG'), ('this', 'DT'), ('serum', 'NN'), ('for', 'IN'), ('few', 'JJ'), ('days', 'NNS'), ('now', 'RB'), ('and', 'CC'), ('can', 'MD'), ('already', 'RB'), ('see', 'VB'), ('great', 'JJ'), ('difference', 'NN'), ('use', 'NN'), ('it', 'PRP'), ('right', 'RB'), ('after', 'IN'), ('use', 'VB'), ('the', 'DT'), ('gel', 'NN'), ('wash', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('makes', 'VBZ'), ('my', 'PRP$'), ('skin', 'JJ'), ('feel', 'NN'), ('soft', 'JJ'), ('moisturized', 'VBN'), ('and', 'CC'), ('fresh', 'JJ'), ('also', 'RB'), ('love', 'VBP'), ('how', 'WRB'), ('glowing', 'VBG'), ('it', 'PRP'), ('makes', 'VBZ'), ('my', 'PRP$'), ('skin', 'JJ'), ('look', 'VBP'), ('one', 'CD'), ('of', 'IN'), ('my', 'PRP$'), ('favourite', 'JJ'), ('things', 'NNS'), ('about', 'IN'), ('this', 'DT'), ('serum', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('a', 'DT'), ('in', 'IN'), ('formula', 'NN'), ('would', 'MD'), ('totally', 'RB'), ('recommend', 'VB'), ('using', 'VBG'), ('this', 'DT')]\n",
      "final i ve been using this serum for few days now and can already see great differenceuse it right after use the gelwash and it makes my skin feel soft moisturized and fresh also love how glowing it makes my skin look one of my favourite things about this serum is that it a in formula would totally recommend using this\n",
      "[('using', 'VBG'), ('serum', 'JJ'), ('days', 'NNS'), ('already', 'RB'), ('see', 'VBP'), ('great', 'JJ'), ('differenceuse', 'NN'), ('right', 'NN'), ('use', 'NN'), ('gelwash', 'NN'), ('makes', 'VBZ'), ('skin', 'JJ'), ('feel', 'VB'), ('soft', 'JJ'), ('moisturized', 'VBN'), ('fresh', 'NN'), ('also', 'RB'), ('love', 'VBP'), ('glowing', 'VBG'), ('makes', 'VBZ'), ('skin', 'JJ'), ('look', 'VB'), ('one', 'CD'), ('favourite', 'JJ'), ('things', 'NNS'), ('serum', 'JJ'), ('formula', 'NN'), ('would', 'MD'), ('totally', 'RB'), ('recommend', 'VB'), ('using', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    " #Create a def to remove all the upper lower case, punctuations, and extra white space\n",
    "\n",
    "def preprocess(review):\n",
    "  sentence = review\n",
    "  sentence = re.sub('[^a-zA-Z]',' ',sentence)\n",
    "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ',sentence)\n",
    "  sentence = re.sub(r'\\s+', ' ',sentence)\n",
    "\n",
    "  return sentence\n",
    "\n",
    "temp=preprocess(txt)\n",
    "sentList=nltk.sent_tokenize(temp)\n",
    "\n",
    "#Word tokenize and Part-of-speech Tag each word\n",
    "\n",
    "for line in sentList:\n",
    "    txt_list = nltk.word_tokenize(line)\n",
    "    taggedList = nltk.pos_tag(txt_list)\n",
    "print(taggedList)\n",
    "\n",
    "sentList\n",
    "\n",
    "#Join words with two nouns together(E.g. hair product = hairproduct)then pos tag everything again\n",
    "\n",
    "newwordList = []\n",
    "flag = 0\n",
    "for i in range(0,len(taggedList)-1):\n",
    "    if(taggedList[i][1]==\"NN\" and taggedList[i+1][1]==\"NN\"):\n",
    "        newwordList.append(taggedList[i][0]+taggedList[i+1][0])\n",
    "        flag=1\n",
    "    else:\n",
    "        if(flag==1):\n",
    "            flag=0\n",
    "            continue\n",
    "        newwordList.append(taggedList[i][0])\n",
    "        if(i==len(taggedList)-2):\n",
    "            newwordList.append(taggedList[i+1][0])\n",
    "finaltxt = ' '.join(word for word in newwordList)\n",
    "print('final',finaltxt)\n",
    "\n",
    "sentList = nltk.sent_tokenize(finaltxt)\n",
    "for line in sentList:\n",
    "    txt_list = nltk.word_tokenize(line)\n",
    "    taggedList = nltk.pos_tag(txt_list)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "new_txt_list = nltk.word_tokenize(finaltxt)\n",
    "wordsList = [w for w in new_txt_list if not w in stop_words]\n",
    "taggedList = nltk.pos_tag(wordsList)\n",
    "\n",
    "print(taggedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('using', 'VBG'),\n",
       " ('serum', 'JJ'),\n",
       " ('days', 'NNS'),\n",
       " ('already', 'RB'),\n",
       " ('see', 'VBP'),\n",
       " ('great', 'JJ'),\n",
       " ('differenceuse', 'NN'),\n",
       " ('right', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('gelwash', 'NN'),\n",
       " ('makes', 'VBZ'),\n",
       " ('skin', 'JJ'),\n",
       " ('feel', 'VB'),\n",
       " ('soft', 'JJ'),\n",
       " ('moisturized', 'VBN'),\n",
       " ('fresh', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('love', 'VBP'),\n",
       " ('glowing', 'VBG'),\n",
       " ('makes', 'VBZ'),\n",
       " ('skin', 'JJ'),\n",
       " ('look', 'VB'),\n",
       " ('one', 'CD'),\n",
       " ('favourite', 'JJ'),\n",
       " ('things', 'NNS'),\n",
       " ('serum', 'JJ'),\n",
       " ('formula', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('totally', 'RB'),\n",
       " ('recommend', 'VB'),\n",
       " ('using', 'VBG')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(taggedList)):\n",
    "#     if taggedList[i][1]=='NN':\n",
    "#         print('yes')\n",
    "#         new=(taggedList[i][0],'JJ')\n",
    "#         taggedList[i] = new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(finaltxt)\n",
    "dep_node = []\n",
    "for dep_edge in doc.sentences[0].dependencies:\n",
    "    dep_node.append([dep_edge[2].text, dep_edge[0].id, dep_edge[1]])\n",
    "for i in range(0, len(dep_node)):\n",
    "    if (int(dep_node[i][1]) != 0):\n",
    "        dep_node[i][1] = newwordList[(int(dep_node[i][1]) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('using', 'VBG'), ('serum', 'JJ'), ('days', 'NNS'), ('already', 'RB'), ('see', 'VBP'), ('great', 'JJ'), ('differenceuse', 'NN'), ('right', 'NN'), ('use', 'NN'), ('gelwash', 'NN'), ('makes', 'VBZ'), ('skin', 'JJ'), ('feel', 'VB'), ('soft', 'JJ'), ('moisturized', 'VBN'), ('fresh', 'NN'), ('also', 'RB'), ('love', 'VBP'), ('glowing', 'VBG'), ('makes', 'VBZ'), ('skin', 'JJ'), ('look', 'VB'), ('one', 'CD'), ('favourite', 'JJ'), ('things', 'NNS'), ('serum', 'JJ'), ('formula', 'NN'), ('would', 'MD'), ('totally', 'RB'), ('recommend', 'VB'), ('using', 'VBG')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "featureList = []\n",
    "categories = []\n",
    "totalfeatureList = []\n",
    "print(taggedList)\n",
    "for i in taggedList:\n",
    "    if(i[1]=='JJ' or i[1]=='JJR' or i[1]=='NNS' or i[1]=='RB'):\n",
    "        featureList.append(list(i))\n",
    "        totalfeatureList.append(list(i)) # This list will store all the features for every sentence\n",
    "        categories.append(i[0])\n",
    "#print(featureList)\n",
    "#print(totalfeatureList)\n",
    "#print(categories)\n",
    "\n",
    "fcluster = []\n",
    "for i in featureList:\n",
    "    filist = []\n",
    "    for j in dep_node:\n",
    "        if((j[0]==i[0] or j[1]==i[0]) and (j[2] in [\"nsubj\", \"acl:relcl\", \"obj\", \"dobj\", \"agent\", \"advmod\", \"amod\", \"neg\", \"prep_of\", \"acomp\", \"xcomp\", \"compound\"])):\n",
    "            if(j[0]==i[0]):\n",
    "                filist.append(j[1])\n",
    "            else:\n",
    "                filist.append(j[0])\n",
    "    fcluster.append([i[0], filist])\n",
    "\n",
    "\n",
    "finalcluster = []\n",
    "dic = {}\n",
    "for i in featureList:\n",
    "    dic[i[0]] = i[1]\n",
    "for i in fcluster:\n",
    "    if(dic[i[0]]==\"NN\"):\n",
    "        finalcluster.append(i)\n",
    "print(finalcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serum',\n",
       " 'days',\n",
       " 'already',\n",
       " 'great',\n",
       " 'skin',\n",
       " 'soft',\n",
       " 'also',\n",
       " 'skin',\n",
       " 'favourite',\n",
       " 'things',\n",
       " 'serum',\n",
       " 'totally']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['serum', ['using']],\n",
       " ['days', ['few']],\n",
       " ['already', ['see']],\n",
       " ['great', ['differenceuse']],\n",
       " ['skin', ['makes', 'makes']],\n",
       " ['soft', ['moisturized']],\n",
       " ['also', ['love']],\n",
       " ['skin', ['makes', 'makes']],\n",
       " ['favourite', ['things']],\n",
       " ['things', ['favourite']],\n",
       " ['serum', ['using']],\n",
       " ['totally', ['recommend']]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['serum', 'JJ'],\n",
       " ['days', 'NNS'],\n",
       " ['already', 'RB'],\n",
       " ['great', 'JJ'],\n",
       " ['skin', 'JJ'],\n",
       " ['soft', 'JJ'],\n",
       " ['also', 'RB'],\n",
       " ['skin', 'JJ'],\n",
       " ['favourite', 'JJ'],\n",
       " ['things', 'NNS'],\n",
       " ['serum', 'JJ'],\n",
       " ['totally', 'RB']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
